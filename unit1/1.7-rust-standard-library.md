# Rust Standard Algorithm Libraries

Task: Explore the use of standard algorithm libraries in Rust. Discuss how understanding the underlying algorithms can improve software development practices, and provide examples of integrating Rust’s standard library algorithms into a project.

Rust’s standard library doesn’t just give you data structures and I/O primitives—it ships with a rich set of battle-tested algorithms and iterator adapters that can save you hours of coding, debugging, and profiling. Even better, if you know *how* those algorithms work under the hood, you’ll make smarter choices about when to reach for them (and which variant to use), and avoid subtle performance traps.

---

## Why understanding underlying algorithms matters

1. **Performance predictability**

   * `.sort()` is an adaptive, stable merge-insertion sort (O(n) best, O(n log n) worst).
   * `.sort_unstable()` is an in-place quicksort-variant (O(n log n) average, faster on primitives).
     Knowing that helps you pick the right one: e.g. for large `Vec<i32>` you usually want `sort_unstable()`, whereas if you need stability (preserve equal elements’ order), use `sort()`.

2. **Memory & allocation**

   * Iterator chains (`.map().filter().collect()`) often operate in streaming fashion with minimal allocations.
   * Methods like `.collect::<Vec<_>>()` will reserve up front if they can guess the size, avoiding repeated reallocations.

3. **Algorithmic guarantees**

   * `binary_search()` panics if the slice isn’t sorted—if you only half-sort, it’ll give wrong answers or panic unexpectedly.
   * Knowing that helps you enforce preconditions in your code, or fall back to a linear search when needed.

---

## Integrating std algorithms: code examples

### 1. Sorting & deduplication

```rust
fn unique_sorted(mut v: Vec<String>) -> Vec<String> {
    // We only care about unique file names for a watch list:
    v.sort_unstable();            // fast in-place sort, order among equals doesn’t matter
    v.dedup();                    // removes consecutive duplicates
    v
}

fn example_sort() {
    let files = vec![
        "mod.rs".into(),
        "lib.rs".into(),
        "mod.rs".into(),
        "main.rs".into(),
    ];
    let cleaned = unique_sorted(files);
    println!("{:?}", cleaned); // ["lib.rs", "main.rs", "mod.rs"]
}
```

* **Why it’s nice**: two lines replace a manual sort + loop to skip duplicates.
* **Complexities**: `sort_unstable` is O(n log n) average, `dedup` is O(n).

### 2. Fast look-ups with binary search

```rust
fn find_threshold_position(data: &[f64], threshold: f64) -> usize {
    // precondition: `data` must be sorted ascending
    match data.binary_search_by(|x| x.partial_cmp(&threshold).unwrap()) {
        Ok(idx)  => idx,           // exact match
        Err(idx) => idx,           // insertion point: first element > threshold
    }
}

fn example_search() {
    let temps = vec![10.5, 12.0, 15.4, 18.2, 21.0];
    let pos = find_threshold_position(&temps, 16.0);
    println!("First temp ≥ 16.0 is at index {}", pos); // 3 (18.2)
}
```

* **Key point**: `binary_search_by` avoids panics if you handle the `Err` case.

### 3. Stream processing with iterators

```rust
use std::collections::HashMap;

fn word_counts(text: &str) -> HashMap<&str, usize> {
    text.split_whitespace()
        .map(str::to_lowercase)
        .map(|s| s.trim_matches(|c: char| !c.is_alphanumeric()).to_string())
        .fold(HashMap::new(), |mut acc, word| {
            *acc.entry(word).or_insert(0) += 1;
            acc
        })
}

fn example_iterators() {
    let poem = "Rust rust, go fast! Rust goes fast.";
    let counts = word_counts(poem);
    println!("{:#?}", counts);
    // e.g. {"rust": 3, "go": 1, "fast": 2, "goes": 1}
}
```

* **Why it rocks**: single pass, no intermediate `Vec<String>` needed, pre-reserves the `HashMap` only when you call `fold`.
* **Understanding fold**: you know it’s O(n) time, O(k) space where k is unique words.

### 4. Grouping & windowed algorithms with `chunks` and `windows`

Imagine you need to compute a moving average over sensor readings:

```rust
fn moving_average(data: &[f64], window: usize) -> Vec<f64> {
    data.windows(window)
        .map(|w| w.iter().sum::<f64>() / window as f64)
        .collect()
}

fn example_moving_avg() {
    let readings = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let avg = moving_average(&readings, 3);
    // [2.0, 3.0, 4.0]
    println!("{:?}", avg);
}
```

* **Under the hood**: each call to `windows` is O(1) to set up a slice reference; the `.map` and `.sum` each are O(window), so overall O(n·window).
* If you needed O(n) total, you’d implement a rolling sum manually—but knowing how `windows` works tells you when to swap strategies.

---

## Best practices

* **Always check complexity**: glance at the docs or source to confirm whether it’s O(n), O(n log n), etc.
* **Prefer iterator adapters** over manual loops for clarity, unless you’ve benchmarked and need a hand-optimized version.
* **Benchmark hotspots**: use `cargo bench` or `criterion` to ensure the std algorithms aren’t your bottleneck.
* **Leverage special methods**: `partition`, `partition_point`, `nth_element` (via `select_nth_unstable`)—all built into slices/iterators for specific patterns.

By leaning on Rust’s standard algorithms—and knowing their performance profiles—you minimize bugs, maximize clarity, and harness community-tested optimizations without reinventing the wheel.
