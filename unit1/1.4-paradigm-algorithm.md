# Paradigm Algorithms

Task: Implement examples of divide and conquer, recursive, greedy, and dynamic programming algorithms in Rust. Compare their efficiency and discuss in which scenarios each paradigm is most effective.

## 1. Divide & Conquer: Merge Sort

```rust
fn merge_sort<T: Ord + Clone>(arr: &[T]) -> Vec<T> {
    let n = arr.len();
    if n <= 1 {
        return arr.to_vec();
    }
    let mid = n / 2;
    let left = merge_sort(&arr[..mid]);
    let right = merge_sort(&arr[mid..]);

    // merge two sorted halves
    let mut merged = Vec::with_capacity(n);
    let (mut i, mut j) = (0, 0);
    while i < left.len() && j < right.len() {
        if left[i] <= right[j] {
            merged.push(left[i].clone());
            i += 1;
        } else {
            merged.push(right[j].clone());
            j += 1;
        }
    }
    merged.extend_from_slice(&left[i..]);
    merged.extend_from_slice(&right[j..]);
    merged
}

fn example_merge_sort() {
    let data = vec![5, 2, 8, 1, 9, 3];
    println!("{:?}", merge_sort(&data));
}
```

* **Time:** O(n log n)
* **Space:** O(n)
* **When to use:** Large arrays or lists where you need guaranteed O(n log n) performance and can afford the extra buffer. Great for external sorting (splitting data on disk) or parallelizing splits.

---

## 2. Pure Recursion: Naïve Fibonacci

```rust
fn fib_rec(n: u32) -> u64 {
    match n {
        0 => 0,
        1 => 1,
        _ => fib_rec(n - 1) + fib_rec(n - 2),
    }
}

fn example_fib_rec() {
    println!("{}", fib_rec(30)); // beware: slow for n ≳ 40
}
```

* **Time:** O(2ⁿ) (exponential)
* **Space:** O(n) (call-stack depth)
* **When to use:** Only for teaching or very small n. Pure recursion is easy to write but blows up when subproblems overlap heavily.

---

## 3. Greedy: Coin Change (Canonical U.S. System)

```rust
fn coin_change_greedy(amount: u32) -> Vec<u32> {
    let coins = [25, 10, 5, 1];
    let mut remaining = amount;
    let mut result = Vec::new();
    for &c in &coins {
        let count = remaining / c;
        for _ in 0..count {
            result.push(c);
        }
        remaining %= c;
    }
    result
}

fn example_coin_change() {
    let coins = coin_change_greedy(67);
    println!("{:?}", coins); // [25, 25, 10, 5, 1, 1]
}
```

* **Time:** O(k) where k = number of coin types (here 4)
* **Space:** O(amount/coin\_min) in the worst-case list size
* **When to use:** When a locally optimal choice (take the biggest coin) leads to a global optimum. Works for canonical systems (U.S., euro), interval scheduling, Huffman coding, MST (Kruskal).

---

## 4. Dynamic Programming: Bottom-Up Fibonacci

```rust
fn fib_dp(n: usize) -> u64 {
    if n < 2 {
        return n as u64;
    }
    let mut dp = vec![0u64; n + 1];
    dp[0] = 0;
    dp[1] = 1;
    for i in 2..=n {
        dp[i] = dp[i - 1] + dp[i - 2];
    }
    dp[n]
}

fn example_fib_dp() {
    println!("{}", fib_dp(1_000_000)); // fast, modulo overflow aside
}
```

* **Time:** O(n)
* **Space:** O(n)
* **When to use:** Overlapping subproblems with optimal substructure—knapsack, edit distance, matrix chain multiplication. Whenever naive recursion repeats work, DP saves you by tabulating or memoizing.

---

## 5. Paradigm Comparison

| Paradigm            | Typical Complexity       | When It Shines                                             |
| ------------------- | ------------------------ | ---------------------------------------------------------- |
| Divide & Conquer    | O(n log n), O(n)         | Sorting, FFT, search on sorted data, parallelizable splits |
| Pure Recursion      | Often exponential        | Simple tree/graph traversals, teaching, small n            |
| Greedy              | Often O(n) or O(k log k) | Scheduling, MST, canonical coin change, interval problems  |
| Dynamic Programming | O(n·m) etc.              | Overlapping subproblems: DP on sequences, graphs, knapsack |

* **Divide & Conquer** reduces big problems into independent halves—great for sorting and parallel work.
* **Recursion** matches tree-shaped problems naturally, but beware exponential blow-up without memoization.
* **Greedy** is lightning fast but only correct when “local optimum ⇒ global optimum.”
* **DP** trades space for speed, eliminating redundant work—essential when optimal substructure + overlap occur.

Choose the paradigm by spotting your problem’s structure:

* If you can split evenly → divide & conquer.
* If subcalls don’t overlap → simple recursion is fine.
* If a greedy choice is provably safe → go greedy.
* If subproblems repeat → reach for DP.
