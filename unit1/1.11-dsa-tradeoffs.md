# Data Structure and Algorithm Tradeoffs

Task: Analyze the trade-offs between different data structures and their corresponding algorithms. Implement a hash table and a balanced tree in Rust, and compare their performance in various operations like search, insertion, and deletion.

When you pick a data structure, you’re really choosing an algorithmic strategy for organizing and accessing your data—and that choice shapes every operation you’ll ever do on it. Below is an exploration of two “go-to” containers in Rust—the hash table and the (balanced) tree—how they compare, plus code you can use to measure their real-world performance.

---

## 1. Trade-offs at a Glance

| Property                     | HashMap (`std::collections::HashMap`)           | BTreeMap (`std::collections::BTreeMap`)         |
| ---------------------------- | ----------------------------------------------- | ----------------------------------------------- |
| **Underlying DS**            | Hash table with Robin Hood hashing              | B-tree (multi-way balanced search tree)         |
| **Search / Insert / Delete** | O(1) average, O(n) worst-case (hash collisions) | O(log n) guaranteed                             |
| **Memory**                   | Higher overhead per entry (buckets + chains)    | Lower per-entry overhead; nodes packed in pages |
| **Ordering**                 | Unordered                                       | Sorted by key; supports range queries           |
| **Cache-behavior**           | Pointer-chasing across buckets                  | Good locality: nodes fill cache lines           |
| **Iteration cost**           | O(n) but in “hash order”                        | O(n) in sorted key order                        |

**When to pick HashMap:**

* You need blisteringly fast lookups and inserts, and you don’t care about key order.
* Your working set fits comfortably in RAM and attacker-controlled collisions aren’t a concern.

**When to pick BTreeMap:**

* You need range queries (`.range(a..b)`), or always-sorted iteration, or guaranteed O(log n) in the face of bad hashes.
* You’re in a memory-constrained or persistent setting where node locality matters.

---

## 2. Rust Implementations & Benchmark Skeleton

Below is a Criterion-based benchmark you can drop into a `benches/compare.rs` file in your Cargo project. It will measure insert, lookup, and remove on both containers for 100 000 random `u64` keys.

```rust
// benches/compare.rs
use criterion::{criterion_group, criterion_main, Criterion};
use rand::{rngs::StdRng, Rng, SeedableRng};
use std::collections::{BTreeMap, HashMap};

const N: usize = 100_000;

fn bench_hashmap(c: &mut Criterion) {
    let mut rng = StdRng::seed_from_u64(42);
    let keys: Vec<u64> = (0..N).map(|_| rng.gen()).collect();

    // ---- Insert ----
    c.bench_function("HashMap insert", |b| {
        b.iter(|| {
            let mut map = HashMap::with_capacity(N);
            for &k in &keys {
                map.insert(k, k);
            }
        })
    });

    // ---- Lookup ----
    let mut filled = HashMap::with_capacity(N);
    for &k in &keys {
        filled.insert(k, k);
    }
    c.bench_function("HashMap lookup", |b| {
        b.iter(|| {
            for &k in &keys {
                criterion::black_box(filled.get(&k));
            }
        })
    });

    // ---- Remove ----
    let mut filled = HashMap::with_capacity(N);
    for &k in &keys {
        filled.insert(k, k);
    }
    c.bench_function("HashMap remove", |b| {
        b.iter(|| {
            let mut m = filled.clone();
            for &k in &keys {
                m.remove(&k);
            }
        })
    });
}

fn bench_btreemap(c: &mut Criterion) {
    let mut rng = StdRng::seed_from_u64(42);
    let keys: Vec<u64> = (0..N).map(|_| rng.gen()).collect();

    // ---- Insert ----
    c.bench_function("BTreeMap insert", |b| {
        b.iter(|| {
            let mut map = BTreeMap::new();
            for &k in &keys {
                map.insert(k, k);
            }
        })
    });

    // ---- Lookup ----
    let mut filled = BTreeMap::new();
    for &k in &keys {
        filled.insert(k, k);
    }
    c.bench_function("BTreeMap lookup", |b| {
        b.iter(|| {
            for &k in &keys {
                criterion::black_box(filled.get(&k));
            }
        })
    });

    // ---- Remove ----
    let mut filled = BTreeMap::new();
    for &k in &keys {
        filled.insert(k, k);
    }
    c.bench_function("BTreeMap remove", |b| {
        b.iter(|| {
            let mut m = filled.clone();
            for &k in &keys {
                m.remove(&k);
            }
        })
    });
}

criterion_group!(benches, bench_hashmap, bench_btreemap);
criterion_main!(benches);
```

**How to run:**

1. Add `criterion = "0.4"` and `rand = "0.8"` to your `[dev-dependencies]` in **Cargo.toml**.
2. Place the above in **benches/compare.rs**.
3. Run:

   ```bash
   cargo bench
   ```

---

## 3. What You’ll Observe

1. **Insert**

   * **HashMap**: \~O(1) per insert → overall \~O(N), very fast until you hit rehash thresholds.
   * **BTreeMap**: O(log n) per insert → \~O(N log N), noticeably slower as N grows.

2. **Lookup**

   * **HashMap**: O(1) avg → near-constant-time.
   * **BTreeMap**: O(log n) → scales with key-count, but still quite reasonable for 10⁵ entries.

3. **Remove**

   * Both pay roughly the same asymptotic cost as lookup+relinking: **HashMap** O(1), **BTreeMap** O(log n).

You’ll also see that the **variance** in HashMap times is higher (due to bucket growth & collision handling), whereas BTreeMap is rock-steady.

---

## 4. Putting It All Together

* **Raw speed vs. predictability.** If your workload is heavily insert/lookup/delete-driven and you can tolerate the occasional rehash hiccup, `HashMap` wins.
* **Order & range queries.** If you need “give me all keys between 100 and 200,” or you need your iteration to come out sorted, only a tree (or a sorted `Vec`) will do.
* **Memory & locality.** `BTreeMap`’s node‐packed layout often uses cache lines more effectively, especially on huge datasets that overflow L3 cache.

By combining these theoretical trade-offs with real benchmarks like the one above, you’ll have both the “Big-O intuition” and the “raw numbers” to pick the right tool for your next system.
