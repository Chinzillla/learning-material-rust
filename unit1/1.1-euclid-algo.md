# Euclid’s algorithm

Task: Explain the historical significance of Euclid’s algorithm for computing the greatest common divisor. Provide a sample implementation of this algorithm in Rust, and discuss how it laid the groundwork for more complex algorithms in computer science.


### 1. Why Euclid’s Algorithm Matters

* **Oldest “real” algorithm**: Recorded around 300 BC in Book VII of Euclid’s *Elements*, it’s the earliest nontrivial algorithm we still use today.
* **Algorithmic thinking**: Euclid didn’t just list steps—he proved they always terminate and give the right answer. That emphasis on *procedure + proof* set the tone for millennia of mathematical rigor.
* **Efficiency blueprint**: It wasn’t until the 19th century that Lamé showed the algorithm runs in *O(log n)* steps (based on Fibonacci numbers!). This was one of the first glimpses into measuring how long an algorithm takes.
* **Building block for more**: From the **extended Euclidean** algorithm (finding modular inverses) to polynomial GCDs to fast integer arithmetic in cryptography (RSA key generation), it’s everywhere.

---

### 2. Euclid’s Algorithm in Rust

```rust
/// Compute the greatest common divisor of a and b
fn gcd(mut a: u64, mut b: u64) -> u64 {
    while b != 0 {
        let r = a % b;
        a = b;
        b = r;
    }
    a
}

fn main() {
    let pairs = [(42, 56), (119, 544), (13, 27)];
    for (x, y) in pairs {
        println!("gcd({}, {}) = {}", x, y, gcd(x, y));
    }
}
```

A few notes:

* We use a simple loop and the `%` (modulo) operator.
* By swapping `(a, b) → (b, a % b)` until `b` hits zero, we converge on the GCD.
* Rust’s strong typing (`u64`) and zero-cost abstractions let you write it both safely and really fast.

---

### 3. From Euclid to Modern Algorithms

1. **Extended Euclid**

   * Finds integers `x` and `y` such that `ax + by = gcd(a, b)`.
   * Fundamental to computing modular inverses in cryptography (think RSA and elliptic-curve crypto).

2. **Divide-and-Conquer & Recursion**

   * Euclid’s use of repeated division is an early instance of reducing a big problem into a smaller one—precursor to merge sort, quicksort, FFT, etc.

3. **Complexity Theory’s Roots**

   * Lamé’s 1844 analysis introduced the idea of worst-case steps. Tracking how the algorithm’s steps grow with input size laid groundwork for big-O notation.

4. **Generalizations**

   * **Polynomials**: You can run “Euclid” on polynomials to compute common factors, which underpins computer algebra systems.
   * **Abstract Algebra**: In any Euclidean domain (rings with a division algorithm), you get a version of “Euclid” to compute GCDs—key in algebraic number theory.

In short, Euclid’s algorithm is far more than a classroom exercise—it’s the prototype of what we now call an algorithm: a finite, provably correct procedure with measurable performance. Its footprint is all over modern computing, from secure communications to symbolic math systems.
